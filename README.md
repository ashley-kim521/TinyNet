# TinyNet
Development of my own version of the popular deep learning library PyTorch. A key part of TinyNet is the implementation of Autograd, which is a library for Automatic Differentiation.

The structure of the code is the following:
mytorch........................................................................MyTorch library
nn....................................................................Neural Net-related files
activations.py
batchnorm.py
functional.py
linear.py
loss.py
module.py
sequential.py
optim ................................................................. Optimizer-related files
optimizer.py
sgd.py
autograd engine.py.....................................................Autograd main code
tensor.py.....................................................................Tensor object
mnist.py.....................................................Running MLP on MNIST
